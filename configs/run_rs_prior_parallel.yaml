pipeline_space:
  batch_size: 128
  num_layers:
    lower: 1
    upper: 3
    default: 2
  num_neurons:
    lower: 16
    upper: 256
    default: 128
  learning_rate:
    lower: 0.001
    upper: 0.1
    log: true
    default: 0.01
  weight_decay: 0.01
  optimizer:
    choices: ["adamw", "adam", "sgd"]
    default: "sgd"
  epochs: 10

run_pipeline:
  path: ./hpo_target.py
  name: training_pipeline

searcher: 
  strategy: random_search
  use_priors: true

root_directory: ./neps_output/random_search_prior_parallel
max_evaluations_total: 25
post_run_summary: true
overwrite_working_directory: false